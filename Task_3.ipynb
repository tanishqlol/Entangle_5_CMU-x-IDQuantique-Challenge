{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "464d9248",
      "metadata": {
        "id": "464d9248"
      },
      "outputs": [],
      "source": [
        "# Package Imports - feel free to add what you think might be useful!\n",
        "import requests\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from math import log2\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41bd5b50",
      "metadata": {
        "id": "41bd5b50"
      },
      "source": [
        "## Task 3: Quest for Quantum Randomness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af55384",
      "metadata": {
        "id": "5af55384"
      },
      "source": [
        "### Part A: Truly Different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "edd9a7ea",
      "metadata": {
        "id": "edd9a7ea"
      },
      "outputs": [],
      "source": [
        "#Constants\n",
        "\n",
        "QRNG_API_URL = \"https://qrng.idqloud.com/api/1.0\"\n",
        "API_KEY = \"aTo4BKRvnc49uRWDk034zaua87vGRXKk9TMLdfkI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "67b421a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "67b421a6",
        "outputId": "c3df479a-ec4e-4415-9d95-b43adc6e82da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nUsing the QRNGaaS User Manual provided,\\nwrite Python code to get random numbers from IDQuantique's Quantum Random Number Generators.\\n\\nThe API documentation is available at: https://drive.google.com/file/d/1OkyRUP7HC4dbmi8OvoT4EuvXqRVGdsjD/view\\nYou'll probably reuse this code for Task 4. So write it well!\\n\\nIf you are unfamiliar with writing HTTP requests in Python,\\nhttps://www.w3schools.com/python/module_requests.asp\\n\\nIf you're really stuck, this can definitely help. Though we encourage you to read the documentation yourself!\\nhttps://curlconverter.com/python/\\n\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Using the QRNGaaS User Manual provided,\n",
        "write Python code to get random numbers from IDQuantique's Quantum Random Number Generators.\n",
        "\n",
        "The API documentation is available at: https://drive.google.com/file/d/1OkyRUP7HC4dbmi8OvoT4EuvXqRVGdsjD/view\n",
        "You'll probably reuse this code for Task 4. So write it well!\n",
        "\n",
        "If you are unfamiliar with writing HTTP requests in Python,\n",
        "https://www.w3schools.com/python/module_requests.asp\n",
        "\n",
        "If you're really stuck, this can definitely help. Though we encourage you to read the documentation yourself!\n",
        "https://curlconverter.com/python/\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1628e69",
      "metadata": {
        "id": "d1628e69"
      },
      "source": [
        "### Class for using API for getting random numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c3adb476",
      "metadata": {
        "id": "c3adb476"
      },
      "outputs": [],
      "source": [
        "class QRNGaaS:\n",
        "    def __init__(self, api_key: str):\n",
        "        self.base_url = QRNG_API_URL\n",
        "        self.headers = {\n",
        "            \"X-API-KEY\": api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        self.max_batch_size = 64  # Actual API limit (32 for int, 64 for short)\n",
        "        self.max_double_batch = 16\n",
        "\n",
        "    def get_random_ints_batched(self, quantity: int) -> List[int]:\n",
        "        \"\"\"Get random 32-bit integers with batching to handle API limits\"\"\"\n",
        "        batches = quantity // self.max_batch_size\n",
        "        remainder = quantity % self.max_batch_size\n",
        "\n",
        "        results = []\n",
        "        for _ in range(batches):\n",
        "            results.extend(self._get_batch(self.max_batch_size))\n",
        "\n",
        "        if remainder > 0:\n",
        "            results.extend(self._get_batch(remainder))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _get_batch(self, batch_size: int) -> List[int]:\n",
        "        \"\"\"Get a single batch of random integers\"\"\"\n",
        "        params = {\"quantity\": batch_size}\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                f\"{self.base_url}/short\",\n",
        "                headers=self.headers,\n",
        "                params=params,\n",
        "                timeout=10  # Add timeout to prevent hanging\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            return response.json()[\"data\"]\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"API request failed: {e}\")\n",
        "            return []  # Return empty list on failure\n",
        "\n",
        "    def _get_double_batch(self, batch_size: int, min_val: float, max_val: float) -> List[float]:\n",
        "        params = {\"min\": min_val, \"max\": max_val, \"quantity\": batch_size}\n",
        "        try:\n",
        "            resp = requests.get(f\"{self.base_url}/double\", headers=self.headers, params=params, timeout=10)\n",
        "            resp.raise_for_status()\n",
        "            return resp.json()[\"data\"]\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Double batch request failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_random_doubles_batched(\n",
        "        self,\n",
        "        quantity: int,\n",
        "        min_val: float = 0.0,\n",
        "        max_val: float = 1.0\n",
        "    ) -> List[float]:\n",
        "        \"\"\"\n",
        "        Retrieve 'quantity' true-random doubles in [min_val, max_val), batching to respect API limits.\n",
        "        \"\"\"\n",
        "        full_batches = quantity // self.max_double_batch\n",
        "        remainder = quantity % self.max_double_batch\n",
        "        result: List[float] = []\n",
        "        for _ in range(full_batches):\n",
        "            result.extend(self._get_double_batch(self.max_double_batch, min_val, max_val))\n",
        "        if remainder:\n",
        "            result.extend(self._get_double_batch(remainder, min_val, max_val))\n",
        "        return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8354bf5c",
      "metadata": {
        "id": "8354bf5c"
      },
      "outputs": [],
      "source": [
        "# Initialize QRNG - REPLACE WITH YOUR ACTUAL API KEY\n",
        "qrng = QRNGaaS(API_KEY)\n",
        "\n",
        "# Analysis Parameters\n",
        "SAMPLE_SIZES  = [1,5,10,50,100,250,500,1000,2500,5000,10000,20000]  # Reduced max size due to API limits\n",
        "BIT_LENGTH = 16  # 16-bit integers\n",
        "NUM_TRIALS = 3   # Reduced trials to avoid rate limiting\n",
        "REQUEST_DELAY = 0.1  # Small delay between API calls to avoid rate limiting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a0f70b1",
      "metadata": {
        "id": "6a0f70b1"
      },
      "source": [
        "### Shanon Entropy Calculation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2fe924c7",
      "metadata": {
        "id": "2fe924c7"
      },
      "outputs": [],
      "source": [
        "def shannon_entropy(data: List[int], bit_length: int = BIT_LENGTH) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Shannon entropy for a set of integers,\n",
        "    with results normalized to the theoretical maximum\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate observed probabilities\n",
        "    counts = Counter(data)\n",
        "    probabilities = [count / len(data) for count in counts.values()]\n",
        "\n",
        "    # Calculate raw entropy\n",
        "    raw_entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
        "\n",
        "    # For integers in range [0, 2^bit_length-1], the max entropy should be bit_length\n",
        "    max_possible_entropy = bit_length\n",
        "\n",
        "    return min(raw_entropy, max_possible_entropy)  # Cap at theoretical maximum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb04f3a",
      "metadata": {
        "id": "3bb04f3a"
      },
      "source": [
        "### Bitrate Calculation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "feb1c824",
      "metadata": {
        "id": "feb1c824"
      },
      "outputs": [],
      "source": [
        "def calculate_bitrate(qrng: QRNGaaS, num_values: int, bits_per_value: int) -> Tuple[float, float]:\n",
        "    \"\"\"Calculate bitrate (bits/sec) with proper batching\"\"\"\n",
        "    start_time = time.time()\n",
        "    qrng.get_random_ints_batched(num_values)  # Generate the values\n",
        "    elapsed = time.time() - start_time\n",
        "    total_bits = num_values * bits_per_value\n",
        "    return total_bits / elapsed if elapsed > 0 else 0.0, elapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "04f18019",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04f18019",
        "outputId": "65cdab3d-7e7d-4ec0-c247-f86eee4f44ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"data\":[-18377,-17828,-28465,-18399,-15883,17057,26892,-15540,-25988,2930],\"dataType\":\"int16\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100    95  100    95    0     0    102      0 --:--:-- --:--:-- --:--:--   102\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "To get started, we provide a simple example of how to use the API to generate 10 int16 random numbers.\n",
        "In particular, observe where we pass in the min and max parameters to specify the range of random numbers we want\n",
        "and the quantity parameter to specify how many random numbers we want.\n",
        "Here is the API KEY you will need to use: aTo4BKRvnc49uRWDk034zaua87vGRXKk9TMLdfkI\n",
        "\"\"\"\n",
        "\n",
        "!curl \"https://qrng.idqloud.com/api/1.0/short?max=32767&min=-32768&quantity=10\" -X GET -H \"X-API-KEY: aTo4BKRvnc49uRWDk034zaua87vGRXKk9TMLdfkI\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a854846",
      "metadata": {
        "id": "6a854846"
      },
      "source": [
        "### Getting values from API for selected sample size and calculating its entropy and bitrate value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24226678",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24226678",
        "outputId": "832926d0-694c-447f-a2ea-c6f47c0e5564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running entropy analysis (this may take a while due to API limits)...\n",
            "Sample size: 1, Entropy: -0.00 bits\n",
            "Sample size: 5, Entropy: 2.32 bits\n",
            "Sample size: 10, Entropy: 3.32 bits\n",
            "Sample size: 50, Entropy: 5.64 bits\n",
            "Sample size: 100, Entropy: 6.64 bits\n",
            "Sample size: 250, Entropy: 7.97 bits\n",
            "Sample size: 500, Entropy: 8.96 bits\n",
            "Sample size: 1000, Entropy: 9.95 bits\n",
            "Sample size: 2500, Entropy: 11.25 bits\n",
            "Sample size: 5000, Entropy: 12.21 bits\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "You can paste the other environmental entropy based TRNGs from Task 2 and compare the performance\n",
        "Compare your written QRNG to the previous TRNGs. Be sure to compare them with respect to bitrate and entropy.\n",
        "\"\"\"\n",
        "# Entropy Analysis\n",
        "print(\"Running entropy analysis (this may take a while due to API limits)...\")\n",
        "entropy_values = []\n",
        "for size in SAMPLE_SIZES:\n",
        "    time.sleep(REQUEST_DELAY)  # Be gentle with the API\n",
        "    data = qrng.get_random_ints_batched(size)\n",
        "    if len(data) != size:\n",
        "        print(f\"Warning: Only got {len(data)}/{size} values\")\n",
        "\n",
        "    entropy = shannon_entropy(data, BIT_LENGTH)\n",
        "    entropy_values.append(entropy)\n",
        "    print(f\"Sample size: {size}, Entropy: {entropy:.2f} bits\")\n",
        "\n",
        "# Bitrate Analysis\n",
        "print(\"\\nRunning bitrate analysis...\")\n",
        "bitrates = []\n",
        "test_size = 1000  # Fixed size for bitrate comparison\n",
        "\n",
        "for trial in range(NUM_TRIALS):\n",
        "    time.sleep(REQUEST_DELAY)  # Be gentle with the API\n",
        "    bitrate, elapsed = calculate_bitrate(qrng, test_size, BIT_LENGTH)\n",
        "    if bitrate > 0:  # Only record successful trials\n",
        "        bitrates.append(bitrate)\n",
        "        print(f\"Trial {trial+1}: {bitrate:.2f} bits/sec (took {elapsed:.4f} sec)\")\n",
        "    else:\n",
        "        print(f\"Trial {trial+1} failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fr8uw57uYdiv",
      "metadata": {
        "id": "Fr8uw57uYdiv"
      },
      "source": [
        "# Comparing TRNG data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XGMrhJdjYmGS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGMrhJdjYmGS",
        "outputId": "c1de8f36-d9fa-465f-e697-43d9c9c51164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\anaconda\\envs\\krispy\\lib\\site-packages (2.2.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in c:\\anaconda\\envs\\krispy\\lib\\site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#import reqd libs\n",
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import hashlib\n",
        "import struct\n",
        "from collections import deque\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K42HA0wlY4qW",
      "metadata": {
        "id": "K42HA0wlY4qW"
      },
      "source": [
        "JitterTRNG Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "CKdM0Sb8Y8xA",
      "metadata": {
        "id": "CKdM0Sb8Y8xA"
      },
      "outputs": [],
      "source": [
        "class JitterRNG:\n",
        "    def __init__(self, pool_size=256):\n",
        "        self.entropy_pool = deque(maxlen=pool_size)\n",
        "        self.pool_size = pool_size\n",
        "        self.last_time = None\n",
        "\n",
        "    def _collect_timing_jitter(self, iterations=1000):\n",
        "        \"\"\"Collect entropy from timing variations between CPU operations\"\"\"\n",
        "        jitter_data = []\n",
        "\n",
        "        self.last_time =  time.perf_counter_ns()\n",
        "        #stores a high-resolution timestamp (in nanoseconds) in the self.last_time variable\n",
        "        #used as the starting time to later compute the timing difference (or jitter) between two measurements\n",
        "\n",
        "        for _ in range(iterations):\n",
        "            \"\"\"\n",
        "            We need to introduce variability somehow.\n",
        "            In the following space, do some arbitrary computation to introduce variability.\n",
        "            We're not going to judge this part. Just make it reasonable so your notebook\n",
        "            doesn't take forever to run.\n",
        "            \"\"\"\n",
        "            # TODO: Do some arbitrary computation to introduce variability\n",
        "            x = 0\n",
        "            for i in range(69):\n",
        "              x += (i*420)\n",
        "            \"\"\"\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            current_time = time.perf_counter_ns()  # TODO: Measure the time again\n",
        "           # assert current_time != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "\n",
        "            time_diff = current_time - self.last_time # TODO: Calculate the jitter (timing difference)\n",
        "            # hint: the JitterRNG class has a last_time attribute,\n",
        "            # and you just computed the current time.\n",
        "            #assert time_diff != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "            # Extract the least significant bits of the time difference\n",
        "            # This is where the true randomness comes from\n",
        "            lsb = time_diff & 255 # TODO: Get the lowest 8 bits of time_diff\n",
        "            # hint: bitwise ops\n",
        "            #assert lsb != \"CHANGE ME\" # delete this when you're done\n",
        "            jitter_data.append(lsb)\n",
        "\n",
        "            self.last_time = current_time # TODO: update self.last_time for next iteration\n",
        "            #assert self.last_time != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "        return jitter_data\n",
        "\n",
        "    def fill_entropy_pool(self):\n",
        "        \"\"\"Fill the entropy pool with timing jitter data\"\"\"\n",
        "        # Collect enough jitter samples to fill the pool\n",
        "        jitter_data = self._collect_timing_jitter(self.pool_size)\n",
        "\n",
        "        # Add to the entropy pool\n",
        "        for value in jitter_data:\n",
        "            self.entropy_pool.append(value)\n",
        "\n",
        "        return jitter_data\n",
        "\n",
        "    def get_random_bytes(self, num_bytes=32):\n",
        "        \"\"\"Generate random bytes using the entropy pool\"\"\"\n",
        "        # Make sure we have enough entropy\n",
        "        if len(self.entropy_pool) < self.pool_size:\n",
        "            self.fill_entropy_pool()\n",
        "\n",
        "        # Mix the entropy pool using SHA-256\n",
        "        pool_bytes = bytes(self.entropy_pool)\n",
        "        mixed_entropy = hashlib.sha256(pool_bytes).digest()\n",
        "\n",
        "        # Create an output buffer\n",
        "        result = bytearray()\n",
        "\n",
        "        # Generate requested number of bytes\n",
        "        while len(result) < num_bytes:\n",
        "            # Add more entropy to the pool\n",
        "            self.fill_entropy_pool()\n",
        "\n",
        "            # Mix new entropy with previous hash\n",
        "            pool_bytes = bytes(self.entropy_pool)\n",
        "            h = hashlib.sha256()\n",
        "            h.update(mixed_entropy)\n",
        "            h.update(pool_bytes)\n",
        "            mixed_entropy = h.digest()\n",
        "\n",
        "            # Add to result\n",
        "            result.extend(mixed_entropy)\n",
        "\n",
        "        # Return only the requested number of bytes\n",
        "        return bytes(result[:num_bytes])\n",
        "\n",
        "    def get_random_int(self, min_val=0, max_val=100):\n",
        "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
        "        # Calculate how many bytes we need\n",
        "        range_size = max_val - min_val + 1\n",
        "        if range_size <= 0:\n",
        "            raise ValueError(\"Invalid range\")\n",
        "\n",
        "        # Calculate how many bits we need\n",
        "        bits_needed = range_size.bit_length()\n",
        "        bytes_needed = (bits_needed + 7) // 8\n",
        "\n",
        "        # Get random bytes\n",
        "        random_bytes = self.get_random_bytes(bytes_needed)\n",
        "\n",
        "        # Convert bytes to integer\n",
        "        value = int.from_bytes(random_bytes, byteorder='big')\n",
        "\n",
        "        # Map to our range\n",
        "        return min_val + (value % range_size)\n",
        "\n",
        "    def analyze_randomness(self, sample_size=1000):\n",
        "        \"\"\"Analyze the randomness of the generator\"\"\"\n",
        "        # Generate samples\n",
        "        samples = []\n",
        "        for _ in range(sample_size):\n",
        "            samples.append(self.get_random_int(0, 255))\n",
        "\n",
        "        # Create plots\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # Plot 1: Distribution histogram\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.hist(samples, bins=32, color='blue', alpha=0.7)\n",
        "        plt.title('Distribution of Random Values')\n",
        "        plt.xlabel('Value')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "        # Plot 2: Sequential values\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(samples[:100], '.-', alpha=0.7)\n",
        "        plt.title('First 100 Generated Values')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('Value')\n",
        "\n",
        "        # Plot 3: Scatter plot of consecutive values\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.scatter(samples[:-1], samples[1:], alpha=0.5, s=5)\n",
        "        plt.title('Scatter Plot of Consecutive Values')\n",
        "        plt.xlabel('Value n')\n",
        "        plt.ylabel('Value n+1')\n",
        "\n",
        "        # Plot 4: Autocorrelation\n",
        "        plt.subplot(2, 2, 4)\n",
        "        autocorr = np.correlate(samples, samples, mode='full')\n",
        "        autocorr = autocorr[len(autocorr)//2:]\n",
        "        autocorr = autocorr / autocorr[0]\n",
        "        plt.plot(autocorr[:50])\n",
        "        plt.title('Autocorrelation')\n",
        "        plt.xlabel('Lag')\n",
        "        plt.ylabel('Correlation')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kmwwv74VZEw7",
      "metadata": {
        "id": "kmwwv74VZEw7"
      },
      "source": [
        "Entropy and Bitrate analysis of Jitter TRNG data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "I-wCzsd2ZH_G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-wCzsd2ZH_G",
        "outputId": "c3128eed-b94f-41af-edde-a36f476ff128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample size: 1, Entropy: -0.00 bits\n",
            "Sample size: 5, Entropy: 2.32 bits\n",
            "Sample size: 10, Entropy: 3.32 bits\n",
            "Sample size: 50, Entropy: 5.64 bits\n",
            "Sample size: 100, Entropy: 6.64 bits\n",
            "Sample size: 250, Entropy: 7.97 bits\n",
            "Sample size: 500, Entropy: 8.95 bits\n",
            "Sample size: 1000, Entropy: 9.96 bits\n",
            "Sample size: 2500, Entropy: 11.25 bits\n"
          ]
        }
      ],
      "source": [
        "jitter_trng = JitterRNG()\n",
        "\n",
        "print()\n",
        "jitter_entropy_values = []\n",
        "\n",
        "for size in SAMPLE_SIZES:\n",
        "    data = []\n",
        "    for i in range(size):\n",
        "      data.append(jitter_trng.get_random_int(-32768,32767))\n",
        "    if len(data) != size:\n",
        "        print(f\"Warning: Only got {len(data)}/{size} values\")\n",
        "\n",
        "    entropy = shannon_entropy(data, BIT_LENGTH)\n",
        "    jitter_entropy_values.append(entropy)\n",
        "    print(f\"Sample size: {size}, Entropy: {entropy:.2f} bits\")\n",
        "\n",
        "def calculate_bitrate_jitter(qrng: JitterRNG, num_values: int, bits_per_value: int) -> Tuple[float, float]:\n",
        "    \"\"\"Calculate bitrate (bits/sec) with proper batching\"\"\"\n",
        "    start_time = time.time()\n",
        "    JitterRNG.get_random_int(-32768,32767)  # Generate the values\n",
        "    elapsed = time.time() - start_time\n",
        "    total_bits = num_values * bits_per_value\n",
        "    return total_bits / elapsed if elapsed > 0 else 0.0, elapsed\n",
        "\n",
        "# Bitrate Analysis\n",
        "print(\"\\nRunning bitrate analysis...\")\n",
        "jitter_bitrates = []\n",
        "test_size = 1000  # Fixed size for bitrate comparison\n",
        "\n",
        "for trial in range(NUM_TRIALS):\n",
        "    time.sleep(REQUEST_DELAY)  # Be gentle with the API\n",
        "    bitrate, elapsed = calculate_bitrate_jitter(jitter_trng, test_size, BIT_LENGTH)\n",
        "    if bitrate > 0:  # Only record successful trials\n",
        "        bitrates.append(bitrate)\n",
        "        print(f\"Trial {trial+1}: {bitrate:.2f} bits/sec (took {elapsed:.4f} sec)\")\n",
        "    else:\n",
        "        print(f\"Trial {trial+1} failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "czjV5fvdnkH6",
      "metadata": {
        "id": "czjV5fvdnkH6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pipwin in c:\\anaconda\\envs\\krispy\\lib\\site-packages (0.5.2)\n",
            "Requirement already satisfied: docopt in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (0.6.2)\n",
            "Requirement already satisfied: requests in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (2.32.3)\n",
            "Requirement already satisfied: pyprind in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (2.11.3)\n",
            "Requirement already satisfied: six in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (4.13.4)\n",
            "Requirement already satisfied: js2py in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (0.74)\n",
            "Requirement already satisfied: packaging in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (25.0)\n",
            "Requirement already satisfied: pySmartDL>=1.3.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from pipwin) (1.3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from beautifulsoup4>=4.9.0->pipwin) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from beautifulsoup4>=4.9.0->pipwin) (4.13.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from js2py->pipwin) (5.3.1)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from js2py->pipwin) (2.7.1)\n",
            "Requirement already satisfied: tzdata in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from tzlocal>=1.2->js2py->pipwin) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from requests->pipwin) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from requests->pipwin) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from requests->pipwin) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\krispy\\lib\\site-packages (from requests->pipwin) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyaudio in c:\\anaconda\\envs\\krispy\\lib\\site-packages (0.2.14)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Package Imports\n",
        "%pip install pipwin\n",
        "%pip install pyaudio\n",
        "import pyaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nZnzfeIekmud",
      "metadata": {
        "id": "nZnzfeIekmud"
      },
      "source": [
        "MicrophoneTRNG Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1-uR6TSCkzIQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "1-uR6TSCkzIQ",
        "outputId": "c78b681c-d55a-4789-b255-b062dfe08f51"
      },
      "outputs": [],
      "source": [
        "class MicrophoneRNG:\n",
        "    def __init__(self, sample_rate=44100, chunk_size=1024, format=pyaudio.paInt16):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.chunk_size = chunk_size\n",
        "        self.format = format\n",
        "        self.audio = pyaudio.PyAudio()\n",
        "        self.stream = None\n",
        "        self.entropy_pool = bytearray()\n",
        "\n",
        "    def _start_stream(self):\n",
        "        \"\"\"Start audio stream if not already running\"\"\"\n",
        "        if self.stream is None or not self.stream.is_active():\n",
        "            self.stream = self.audio.open(\n",
        "                format=self.format,\n",
        "                channels=1,\n",
        "                rate=self.sample_rate,\n",
        "                input=True,\n",
        "                frames_per_buffer=self.chunk_size\n",
        "            )\n",
        "\n",
        "    def _stop_stream(self):\n",
        "        \"\"\"Stop audio stream if running\"\"\"\n",
        "        if self.stream is not None and self.stream.is_active():\n",
        "            self.stream.stop_stream()\n",
        "            self.stream.close()\n",
        "            self.stream = None\n",
        "\n",
        "    def collect_entropy(self, duration_seconds=0.5, visualize=False):\n",
        "        \"\"\"Collect entropy from microphone for specified duration\"\"\"\n",
        "        self._start_stream() # TODO: start the stream\n",
        "\n",
        "        frames = []\n",
        "        num_chunks = int(self.sample_rate * duration_seconds // self.chunk_size) # TODO: compute the number of chunks using the sample rate, duration in seconds, and chunk size.\n",
        "        # hint: there is a division involved. make sure to cast to int, or use integer division.\n",
        "\n",
        "\n",
        "        print(f\"Collecting ambient noise for {duration_seconds} seconds...\")\n",
        "\n",
        "        # Read audio data\n",
        "        for _ in range(max(1, num_chunks)):\n",
        "            data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
        "            frames.append(data)\n",
        "\n",
        "        # Convert to numpy array for processing\n",
        "        if self.format == pyaudio.paInt16:\n",
        "            format_size = 2  # bytes per sample\n",
        "            format_char = 'h'  # short integer\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported audio format\")\n",
        "\n",
        "        # Unpack audio data\n",
        "        audio_data = []\n",
        "        for frame in frames:\n",
        "            count = len(frame) // format_size\n",
        "            fmt = f\"{count}{format_char}\"\n",
        "            audio_data.extend(struct.unpack(fmt, frame))\n",
        "\n",
        "        # Extract entropy from least significant bits\n",
        "        raw_entropy = bytearray()\n",
        "        for sample in audio_data:\n",
        "            # Take the least significant byte (where noise is most prominent)\n",
        "\n",
        "            lsb = sample & 0xFF # TODO: Get the lowest 8 bits of sample\n",
        "            # hint: bitwise ops, just like in Part A\n",
        "\n",
        "\n",
        "            raw_entropy.append(lsb)\n",
        "\n",
        "        # Visualize if requested\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "\n",
        "            # Plot raw audio waveform\n",
        "            plt.subplot(2, 1, 1)\n",
        "            plt.plot(audio_data[:1000])\n",
        "            plt.title(\"Raw Audio Waveform (first 1000 samples)\")\n",
        "            plt.xlabel(\"Sample\")\n",
        "            plt.ylabel(\"Amplitude\")\n",
        "\n",
        "            # Plot histogram of the extracted entropy bytes\n",
        "            plt.subplot(2, 1, 2)\n",
        "            plt.hist(raw_entropy, bins=32, color='green', alpha=0.7)\n",
        "            plt.title(\"Distribution of Extracted Entropy Bytes\")\n",
        "            plt.xlabel(\"Byte Value\")\n",
        "            plt.ylabel(\"Frequency\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Add to entropy pool\n",
        "        self.entropy_pool.extend(raw_entropy)\n",
        "\n",
        "        return raw_entropy\n",
        "\n",
        "    def get_random_bytes(self, num_bytes=32):\n",
        "        \"\"\"Generate random bytes from the entropy pool\"\"\"\n",
        "        # Make sure we have enough entropy\n",
        "        while len(self.entropy_pool) < num_bytes * 2:  # Get more than we need\n",
        "            self.collect_entropy(0.1)\n",
        "\n",
        "        # Mix entropy with SHA-256\n",
        "        h = hashlib.sha256()\n",
        "        h.update(self.entropy_pool)\n",
        "\n",
        "        # Get a seed from the hash\n",
        "        seed = h.digest()\n",
        "\n",
        "        # Generate additional random bytes using the seed\n",
        "        result = bytearray()\n",
        "        counter = 0\n",
        "\n",
        "        while len(result) < num_bytes:\n",
        "            # Create a unique input for each iteration\n",
        "            h = hashlib.sha256()\n",
        "            h.update(seed)\n",
        "            h.update(counter.to_bytes(4, byteorder='big'))\n",
        "            result.extend(h.digest())\n",
        "            counter += 1\n",
        "\n",
        "        # Remove used entropy from the pool\n",
        "        self.entropy_pool = self.entropy_pool[num_bytes:]\n",
        "\n",
        "        return bytes(result[:num_bytes])\n",
        "\n",
        "    def get_random_int(self, min_val=0, max_val=100):\n",
        "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
        "        range_size = max_val - min_val + 1\n",
        "        if range_size <= 0:\n",
        "            raise ValueError(\"Invalid range\")\n",
        "\n",
        "        # Calculate how many bits we need\n",
        "        bits_needed = range_size.bit_length()\n",
        "        bytes_needed = (bits_needed + 7) // 8\n",
        "\n",
        "        # Get random bytes\n",
        "        random_bytes = self.get_random_bytes(bytes_needed)\n",
        "\n",
        "        # Convert to integer and map to our range\n",
        "        value = int.from_bytes(random_bytes, byteorder='big')\n",
        "        return min_val + (value % range_size)\n",
        "\n",
        "    def visualize_randomness(self, num_samples=1000):\n",
        "        \"\"\"Generate and visualize random numbers\"\"\"\n",
        "        samples = [self.get_random_int(0, 255) for _ in range(num_samples)]\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # Plot 1: Distribution histogram\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.hist(samples, bins=32, color='blue', alpha=0.7)\n",
        "        plt.title('Distribution of Random Values')\n",
        "        plt.xlabel('Value')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "        # Plot 2: Sequential values\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(samples[:100], '.-', alpha=0.7)\n",
        "        plt.title('First 100 Generated Values')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('Value')\n",
        "\n",
        "        # Plot 3: Scatter plot of consecutive values\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.scatter(samples[:-1], samples[1:], alpha=0.5, s=5)\n",
        "        plt.title('Scatter Plot of Consecutive Values')\n",
        "        plt.xlabel('Value n')\n",
        "        plt.ylabel('Value n+1')\n",
        "\n",
        "        # Plot 4: Autocorrelation\n",
        "        plt.subplot(2, 2, 4)\n",
        "        autocorr = np.correlate(samples, samples, mode='full')\n",
        "        autocorr = autocorr[len(autocorr)//2:]\n",
        "        autocorr = autocorr / autocorr[0]\n",
        "        plt.plot(autocorr[:50])\n",
        "        plt.title('Autocorrelation')\n",
        "        plt.xlabel('Lag')\n",
        "        plt.ylabel('Correlation')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Clean up when object is destroyed\"\"\"\n",
        "        self._stop_stream()\n",
        "        self.audio.terminate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7TUw2r4Xk0iZ",
      "metadata": {
        "id": "7TUw2r4Xk0iZ"
      },
      "source": [
        "Entropy Analysis of data from Microphone TRNG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "-iD8Xs2sk_yt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-iD8Xs2sk_yt",
        "outputId": "b6a79d80-56cc-4c0c-98ae-69004a7723e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ambient noise for 0.1 seconds...\n",
            "Sample size: 1, Entropy: -0.00 bits\n",
            "Sample size: 5, Entropy: 2.32 bits\n",
            "Sample size: 10, Entropy: 3.32 bits\n",
            "Sample size: 50, Entropy: 5.64 bits\n",
            "Sample size: 100, Entropy: 6.64 bits\n",
            "Sample size: 250, Entropy: 7.97 bits\n",
            "Sample size: 500, Entropy: 8.94 bits\n",
            "Collecting ambient noise for 0.1 seconds...\n",
            "Sample size: 1000, Entropy: 9.96 bits\n",
            "Collecting ambient noise for 0.1 seconds...\n",
            "Collecting ambient noise for 0.1 seconds...\n",
            "Sample size: 2500, Entropy: 11.25 bits\n"
          ]
        }
      ],
      "source": [
        "mic_trng = MicrophoneRNG()\n",
        "\n",
        "\n",
        "mic_entropy_values = []\n",
        "\n",
        "for size in SAMPLE_SIZES:\n",
        "    data = []\n",
        "    for i in range(size):\n",
        "      data.append(mic_trng.get_random_int(-32768,32767))\n",
        "    if len(data) != size:\n",
        "        print(f\"Warning: Only got {len(data)}/{size} values\")\n",
        "\n",
        "    entropy = shannon_entropy(data, BIT_LENGTH)\n",
        "    mic_entropy_values.append(entropy)\n",
        "    print(f\"Sample size: {size}, Entropy: {entropy:.2f} bits\")\n",
        "\n",
        "def calculate_bitrate_microphone(micrng: MicrophoneRNG, num_values: int, bits_per_value: int) -> Tuple[float, float]:\n",
        "    \"\"\"Calculate bitrate (bits/sec) with proper batching\"\"\"\n",
        "    start_time = time.time()\n",
        "    MicrophoneRNG.get_random_int(-32768,32767)  # Generate the values\n",
        "    elapsed = time.time() - start_time\n",
        "    total_bits = num_values * bits_per_value\n",
        "    return total_bits / elapsed if elapsed > 0 else 0.0, elapsed\n",
        "\n",
        "# Bitrate Analysis\n",
        "print(\"\\nRunning bitrate analysis...\")\n",
        "mic_bitrates = []\n",
        "test_size = 1000  # Fixed size for bitrate comparison\n",
        "\n",
        "for trial in range(NUM_TRIALS):\n",
        "    time.sleep(REQUEST_DELAY)  # Be gentle with the API\n",
        "    bitrate, elapsed = calculate_bitrate_microphone(mic_trng, test_size, BIT_LENGTH)\n",
        "    if bitrate > 0:  # Only record successful trials\n",
        "        bitrates.append(bitrate)\n",
        "        print(f\"Trial {trial+1}: {bitrate:.2f} bits/sec (took {elapsed:.4f} sec)\")\n",
        "    else:\n",
        "        print(f\"Trial {trial+1} failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_AaSpcPInws-",
      "metadata": {
        "id": "_AaSpcPInws-"
      },
      "source": [
        "Thermal TRNG Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "jmrgHvNln-s8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmrgHvNln-s8",
        "outputId": "bac6d22e-8cc9-4e34-f01f-20d4e8881dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psutil in c:\\anaconda\\envs\\krispy\\lib\\site-packages (7.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Package Imports\n",
        "%pip install psutil\n",
        "import psutil\n",
        "import platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "gNIbJ78On_sB",
      "metadata": {
        "id": "gNIbJ78On_sB"
      },
      "outputs": [],
      "source": [
        "class ThermalRNG:\n",
        "    def __init__(self, pool_size=256):\n",
        "        self.entropy_pool = deque(maxlen=pool_size)\n",
        "        self.pool_size = pool_size\n",
        "        self.temperature_history = []\n",
        "        self.has_temperature_sensor = self._check_sensor_availability()\n",
        "\n",
        "    def _check_sensor_availability(self):\n",
        "        \"\"\"Check if temperature sensors are available\"\"\"\n",
        "        try:\n",
        "            # Try to get temperatures\n",
        "            temps = self._get_temperature_data()\n",
        "            return len(temps) > 0\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def _get_temperature_data(self):\n",
        "        \"\"\"Get temperature data from system sensors\"\"\"\n",
        "        try:\n",
        "            if platform.system() == 'Windows':\n",
        "                try:\n",
        "                    import wmi\n",
        "                    w = wmi.WMI(namespace=\"root\\\\wmi\")\n",
        "                    temperature_info = w.MSAcpi_ThermalZoneTemperature()\n",
        "                    if temperature_info:  # Check if we got any data\n",
        "                        temps = [float(item.CurrentTemperature)/10.0 - 273.15 \n",
        "                                for item in temperature_info]\n",
        "                        return temps\n",
        "                except Exception as e:\n",
        "                    # Fallback to alternative Windows temperature sources\n",
        "                    pass\n",
        "                \n",
        "                # Try alternative WMI classes\n",
        "                try:\n",
        "                    w = wmi.WMI(namespace=\"root\\\\OpenHardwareMonitor\")\n",
        "                    sensors = w.Sensor()\n",
        "                    temps = [float(s.Value) for s in sensors \n",
        "                            if s.SensorType == u'Temperature']\n",
        "                    if temps:\n",
        "                        return temps\n",
        "                except:\n",
        "                    pass\n",
        "            \n",
        "            elif platform.system() == 'Linux':\n",
        "                # Use psutil on Linux\n",
        "                temperatures = psutil.sensors_temperatures()\n",
        "                temps = []\n",
        "                for name, entries in temperatures.items():\n",
        "                    for entry in entries:\n",
        "                        if entry.current is not None:\n",
        "                            temps.append(entry.current)\n",
        "                return temps\n",
        "            elif platform.system() == 'Darwin':  # macOS\n",
        "                # macOS temperature requires additional libraries\n",
        "                # This is a simplified fallback using CPU metrics as a proxy for temperature\n",
        "                cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
        "                return cpu_percent  # Using CPU load as a proxy for temperature\n",
        "            else:\n",
        "                return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting temperature data: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _get_system_load(self):\n",
        "        \"\"\"Get system load information as a source of entropy\"\"\"\n",
        "        data = []\n",
        "\n",
        "        # CPU usage\n",
        "        cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
        "        data.extend(cpu_percent)\n",
        "\n",
        "        # Memory usage\n",
        "        memory = psutil.virtual_memory()\n",
        "        data.append(memory.percent)\n",
        "\n",
        "        # Disk usage\n",
        "        disk = psutil.disk_usage('/')\n",
        "        data.append(disk.percent)\n",
        "\n",
        "        # Network IO counters\n",
        "        net = psutil.net_io_counters()\n",
        "        data.extend([net.bytes_sent % 256, net.bytes_recv % 256])\n",
        "\n",
        "        return data\n",
        "\n",
        "    def collect_entropy(self, iterations=10, delay=0.1):\n",
        "        \"\"\"Collect entropy from temperature and system metrics\"\"\"\n",
        "        #print(\"Collecting entropy from system metrics...\")\n",
        "\n",
        "        raw_entropy = []\n",
        "\n",
        "        for _ in range(iterations):\n",
        "            temps = self._get_temperature_data() # TODO: Get temperature data\n",
        "            #assert temps != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "            # If temperature sensors are available, use them\n",
        "            if temps and len(temps) > 0:\n",
        "                self.has_temperature_sensor = True\n",
        "                for temp in temps:\n",
        "                    # Extract fractional part of temperature (most random part)\n",
        "                    frac_part = int((temp % 1) * 256)\n",
        "                    lsb = frac_part & 255 # TODO: Get the lowest 8 bits of frac_part\n",
        "                    # hint: bitwise ops, just like in Part A\n",
        "                    #assert lsb != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "                    raw_entropy.append(lsb)\n",
        "                    self.temperature_history.append(temp)\n",
        "\n",
        "            # Always collect system load data as additional entropy\n",
        "            system_data = self._get_system_load()\n",
        "            for value in system_data:\n",
        "                # Extract least significant bits\n",
        "                lsb = int(value) & 255 # TODO: Get the lowest 8 bits of int(value)\n",
        "                # hint: bitwise ops, just like in Part A\n",
        "                #assert lsb != \"CHANGE ME\" # delete this when you're done\n",
        "\n",
        "                raw_entropy.append(lsb)\n",
        "\n",
        "            # Small delay to allow for changes in system state\n",
        "            time.sleep(delay)\n",
        "\n",
        "        # Add to entropy pool\n",
        "        for value in raw_entropy:\n",
        "            self.entropy_pool.append(value)\n",
        "\n",
        "        return raw_entropy\n",
        "    def ensure_entropy(self, min_required=128):\n",
        "        \"\"\"Ensure we have enough entropy in the pool\"\"\"\n",
        "        if len(self.entropy_pool) < min_required:\n",
        "            self.collect_entropy(iterations=max(1, (min_required - len(self.entropy_pool)) // 10))\n",
        "\n",
        "    def get_random_bytes(self, num_bytes=32):\n",
        "        \"\"\"Generate random bytes from the entropy pool\"\"\"\n",
        "        # Make sure we have enough entropy\n",
        "        self.ensure_entropy(num_bytes * 2)\n",
        "\n",
        "        # Mix entropy with SHA-256\n",
        "        h = hashlib.sha256()\n",
        "        h.update(bytes(self.entropy_pool))\n",
        "\n",
        "        # Get a seed from the hash\n",
        "        seed = h.digest()\n",
        "\n",
        "        # Generate additional random bytes using the seed\n",
        "        result = bytearray()\n",
        "        counter = 0\n",
        "\n",
        "        while len(result) < num_bytes:\n",
        "            # Create a unique input for each iteration\n",
        "            h = hashlib.sha256()\n",
        "            h.update(seed)\n",
        "            h.update(counter.to_bytes(4, byteorder='big'))\n",
        "            result.extend(h.digest())\n",
        "            counter += 1\n",
        "\n",
        "        # Collect more entropy for future use\n",
        "        self.collect_entropy(iterations=2)\n",
        "\n",
        "        return bytes(result[:num_bytes])\n",
        "\n",
        "    def get_random_int(self, min_val=0, max_val=100):\n",
        "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
        "        range_size = max_val - min_val + 1\n",
        "        if range_size <= 0:\n",
        "            raise ValueError(\"Invalid range\")\n",
        "\n",
        "        # Calculate how many bits we need\n",
        "        bits_needed = range_size.bit_length()\n",
        "        bytes_needed = (bits_needed + 7) // 8\n",
        "\n",
        "        # Get random bytes\n",
        "        random_bytes = self.get_random_bytes(bytes_needed)\n",
        "\n",
        "        # Convert to integer and map to our range\n",
        "        value = int.from_bytes(random_bytes, byteorder='big')\n",
        "        return min_val + (value % range_size)\n",
        "\n",
        "    def analyze_entropy_source(self):\n",
        "        \"\"\"Analyze and visualize the entropy sources\"\"\"\n",
        "        # Collect some entropy first\n",
        "        if len(self.entropy_pool) < 100:\n",
        "            self.collect_entropy(iterations=20)\n",
        "\n",
        "        # Convert deque to list for analysis\n",
        "        entropy_data = list(self.entropy_pool)\n",
        "\n",
        "        # Create plots\n",
        "        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Plot 1: Histogram of entropy values\n",
        "        axs[0, 0].hist(entropy_data, bins=50, density=True, alpha=0.7)\n",
        "        axs[0, 0].set_title('Distribution of Entropy Values')\n",
        "        axs[0, 0].set_xlabel('Value')\n",
        "        axs[0, 0].set_ylabel('Frequency')\n",
        "        axs[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 2: Time series of values\n",
        "        axs[0, 1].plot(entropy_data, '-o', markersize=3, alpha=0.7)\n",
        "        axs[0, 1].set_title('Entropy Values over Collection Period')\n",
        "        axs[0, 1].set_xlabel('Sample Index')\n",
        "        axs[0, 1].set_ylabel('Value')\n",
        "        axs[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: Temperature history if available\n",
        "        if self.has_temperature_sensor and len(self.temperature_history) > 0:\n",
        "            axs[1, 0].plot(self.temperature_history, '-o', markersize=3, color='red', alpha=0.7)\n",
        "            axs[1, 0].set_title('Temperature History')\n",
        "            axs[1, 0].set_xlabel('Sample Index')\n",
        "            axs[1, 0].set_ylabel('Temperature (C)')\n",
        "            axs[1, 0].grid(True, alpha=0.3)\n",
        "        else:\n",
        "            axs[1, 0].text(0.5, 0.5, 'No temperature data available',\n",
        "                          horizontalalignment='center', verticalalignment='center',\n",
        "                          transform=axs[1, 0].transAxes, fontsize=14)\n",
        "\n",
        "        # Plot 4: Autocorrelation (to check for patterns)\n",
        "        if len(entropy_data) > 10:\n",
        "            max_lag = min(50, len(entropy_data) // 2)\n",
        "            autocorr = [np.corrcoef(entropy_data[:-i], entropy_data[i:])[0, 1]\n",
        "                        if i > 0 else 1.0 for i in range(max_lag)]\n",
        "\n",
        "            axs[1, 1].bar(range(max_lag), autocorr, alpha=0.7)\n",
        "            axs[1, 1].set_title('Autocorrelation Analysis')\n",
        "            axs[1, 1].set_xlabel('Lag')\n",
        "            axs[1, 1].set_ylabel('Correlation Coefficient')\n",
        "            axs[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "            # Add horizontal lines for significance levels (roughly 95% confidence)\n",
        "            sig_level = 1.96 / np.sqrt(len(entropy_data))\n",
        "            axs[1, 1].axhline(y=sig_level, color='r', linestyle='--', alpha=0.5)\n",
        "            axs[1, 1].axhline(y=-sig_level, color='r', linestyle='--', alpha=0.5)\n",
        "        else:\n",
        "            axs[1, 1].text(0.5, 0.5, 'Not enough data for autocorrelation',\n",
        "                          horizontalalignment='center', verticalalignment='center',\n",
        "                          transform=axs[1, 1].transAxes, fontsize=14)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Basic statistical analysis\n",
        "        print(\"\\nEntropy Source Analysis:\")\n",
        "        print(f\"Number of samples: {len(entropy_data)}\")\n",
        "        if len(entropy_data) > 0:\n",
        "            print(f\"Mean: {np.mean(entropy_data):.2f}\")\n",
        "            print(f\"Standard Deviation: {np.std(entropy_data):.2f}\")\n",
        "            print(f\"Min: {np.min(entropy_data)}\")\n",
        "            print(f\"Max: {np.max(entropy_data)}\")\n",
        "\n",
        "        # Run basic entropy tests if enough data\n",
        "        if len(entropy_data) >= 100:\n",
        "            # Simple frequency test (values should be roughly uniformly distributed)\n",
        "            hist, _ = np.histogram(entropy_data, bins=16, range=(0, 255))\n",
        "            chi_squared = np.sum((hist - len(entropy_data)/16)**2 / (len(entropy_data)/16))\n",
        "            print(f\"\\nChi-squared uniformity test: {chi_squared:.2f}\")\n",
        "            print(\"(Lower values suggest better uniformity)\")\n",
        "\n",
        "            # Serial correlation test\n",
        "            serial_corr = np.corrcoef(entropy_data[:-1], entropy_data[1:])[0, 1]\n",
        "            print(f\"Serial correlation: {serial_corr:.4f}\")\n",
        "            print(\"(Values close to zero suggest good randomness)\")\n",
        "\n",
        "        return entropy_data\n",
        "\n",
        "    def generate_random_sequence(self, length=100, min_val=0, max_val=255):\n",
        "        \"\"\"Generate a sequence of random numbers\"\"\"\n",
        "        return [self.get_random_int(min_val, max_val) for _ in range(length)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ikZWX3deoOD8",
      "metadata": {
        "id": "ikZWX3deoOD8"
      },
      "source": [
        "Entropy Analysis of Thermal TRNG data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VgPJlUV5oNtn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "VgPJlUV5oNtn",
        "outputId": "440e39b3-ca56-4e2a-8853-4dd26a1e96aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample size: 1, Entropy: -0.00 bits\n",
            "Sample size: 5, Entropy: 2.32 bits\n",
            "Sample size: 10, Entropy: 3.32 bits\n",
            "Sample size: 50, Entropy: 5.64 bits\n",
            "Sample size: 100, Entropy: 6.64 bits\n",
            "Sample size: 250, Entropy: 7.97 bits\n",
            "Sample size: 500, Entropy: 8.97 bits\n"
          ]
        }
      ],
      "source": [
        "thermal_trng = ThermalRNG()\n",
        "\n",
        "\n",
        "thermal_entropy_values = []\n",
        "\n",
        "for size in SAMPLE_SIZES:\n",
        "    data = []\n",
        "    for i in range(size):\n",
        "      data.append(thermal_trng.get_random_int(-32768,32767))\n",
        "    if len(data) != size:\n",
        "        print(f\"Warning: Only got {len(data)}/{size} values\")\n",
        "\n",
        "    entropy = shannon_entropy(data, BIT_LENGTH)\n",
        "    thermal_entropy_values.append(entropy)\n",
        "    print(f\"Sample size: {size}, Entropy: {entropy:.2f} bits\")\n",
        "\n",
        "\n",
        "def calculate_bitrate_thermal(micrng: ThermalRNG, num_values: int, bits_per_value: int) -> Tuple[float, float]:\n",
        "    \"\"\"Calculate bitrate (bits/sec) with proper batching\"\"\"\n",
        "    start_time = time.time()\n",
        "    ThermalRNG.get_random_int(-32768,32767)  # Generate the values\n",
        "    elapsed = time.time() - start_time\n",
        "    total_bits = num_values * bits_per_value\n",
        "    return total_bits / elapsed if elapsed > 0 else 0.0, elapsed\n",
        "\n",
        "# Bitrate Analysis\n",
        "print(\"\\nRunning bitrate analysis...\")\n",
        "thermal_bitrates = []\n",
        "test_size = 1000  # Fixed size for bitrate comparison\n",
        "\n",
        "for trial in range(NUM_TRIALS):\n",
        "    time.sleep(REQUEST_DELAY)  # Be gentle with the API\n",
        "    bitrate, elapsed = calculate_bitrate_thermal(thermal_trng, test_size, BIT_LENGTH)\n",
        "    if bitrate > 0:  # Only record successful trials\n",
        "        bitrates.append(bitrate)\n",
        "        print(f\"Trial {trial+1}: {bitrate:.2f} bits/sec (took {elapsed:.4f} sec)\")\n",
        "    else:\n",
        "        print(f\"Trial {trial+1} failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c92687",
      "metadata": {
        "id": "c4c92687"
      },
      "source": [
        "### Plotting Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "da92daab",
      "metadata": {
        "id": "da92daab",
        "outputId": "8db2d061-6abb-4592-9988-232e8773b3f9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'thermal_entropy_values' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Thermal Entropy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(SAMPLE_SIZES, \u001b[43mthermal_entropy_values\u001b[49m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mBIT_LENGTH, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdeal Entropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThermal Entropy vs Sample Size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'thermal_entropy_values' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Entropy Plots ---\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Thermal Entropy\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(SAMPLE_SIZES, thermal_entropy_values, marker='s', color='purple')\n",
        "plt.axhline(y=BIT_LENGTH, color='red', linestyle='--', label='Ideal Entropy')\n",
        "plt.title('Thermal Entropy vs Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Shannon Entropy (bits)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Mic Entropy\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(SAMPLE_SIZES, mic_entropy_values, marker='q', color='green')\n",
        "plt.axhline(y=BIT_LENGTH, color='red', linestyle='--', label='Ideal Entropy')\n",
        "plt.title('Mic Entropy vs Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Shannon Entropy (bits)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Jitter Entropy\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(SAMPLE_SIZES, jitter_entropy_values, marker='p', color='red')\n",
        "plt.axhline(y=BIT_LENGTH, color='red', linestyle='--', label='Ideal Entropy')\n",
        "plt.title('Jitter Entropy vs Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Shannon Entropy (bits)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Bitrate Boxplots ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "bitrates_data = []\n",
        "labels = []\n",
        "\n",
        "if thermal_bitrates:\n",
        "    bitrates_data.append(thermal_bitrates)\n",
        "    labels.append('Thermal')\n",
        "\n",
        "if mic_bitrates:\n",
        "    bitrates_data.append(mic_bitrates)\n",
        "    labels.append('Mic')\n",
        "\n",
        "if jitter_bitrates:\n",
        "    bitrates_data.append(jitter_bitrates)\n",
        "    labels.append('Jitter')\n",
        "\n",
        "if bitrates_data:\n",
        "    plt.boxplot(bitrates_data, labels=labels)\n",
        "    plt.ylabel('Bitrate (bits/sec)')\n",
        "    plt.title('Bitrate Distribution by Source')\n",
        "    plt.grid(True)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No successful bitrate measurements',\n",
        "             ha='center', va='center', fontsize=12)\n",
        "    plt.title('Bitrate Measurement Failed')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEntropy Summary:\")\n",
        "for label, entropy_vals in zip([\"Thermal\", \"Mic\", \"Jitter\"],\n",
        "                               [thermal_entropy_values, mic_entropy_values, jitter_entropy_values]):\n",
        "    for size, val in zip(SAMPLE_SIZES, entropy_vals):\n",
        "        print(f\"{label} - Size {size:6d}: {val:.2f} bits (ideal: {BIT_LENGTH} bits)\")\n",
        "    print()\n",
        "\n",
        "def summarize_bitrate(source_name, data):\n",
        "    print(f\"{source_name} Bitrate Summary:\")\n",
        "    print(f\"  Mean   : {np.mean(data):.2f} bits/sec\")\n",
        "    print(f\"  Std Dev: {np.std(data):.2f} bits/sec\")\n",
        "    print(f\"  Min    : {np.min(data):.2f} bits/sec\")\n",
        "    print(f\"  Max    : {np.max(data):.2f} bits/sec\")\n",
        "    print()\n",
        "\n",
        "if thermal_bitrates:\n",
        "    summarize_bitrate(\"Thermal\", thermal_bitrates)\n",
        "if mic_bitrates:\n",
        "    summarize_bitrate(\"Mic\", mic_bitrates)\n",
        "if jitter_bitrates:\n",
        "    summarize_bitrate(\"Jitter\", jitter_bitrates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee04daba",
      "metadata": {
        "id": "ee04daba"
      },
      "source": [
        "### Part B: Easy as Pi!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0155461",
      "metadata": {
        "id": "b0155461"
      },
      "outputs": [],
      "source": [
        "def estimate_pi_qrng(num_points: int, qrng: QRNGaaS) -> float:\n",
        "    circle_points = 0\n",
        "    square_points = 0\n",
        "\n",
        "    # Generate x and y coordinates in batches\n",
        "    points_per_batch = 1000  # Adjust based on API limits and performance\n",
        "    for i in range(0, num_points, points_per_batch):\n",
        "        batch_size = min(points_per_batch, num_points - i)\n",
        "\n",
        "        # Fetch random x and y coordinates in [-1, 1)\n",
        "        rand_x = qrng.get_random_doubles_batched(batch_size, -1.0, 1.0)\n",
        "        rand_y = qrng.get_random_doubles_batched(batch_size, -1.0, 1.0)\n",
        "\n",
        "        if len(rand_x) != batch_size or len(rand_y) != batch_size:\n",
        "            print(f\"Warning: Insufficient random numbers received for batch {i}\")\n",
        "            continue\n",
        "\n",
        "        # Process each point in the batch\n",
        "        for x, y in zip(rand_x, rand_y):\n",
        "            origin_dist = x**2 + y**2\n",
        "            if origin_dist <= 1:\n",
        "                circle_points += 1\n",
        "            square_points += 1\n",
        "\n",
        "    # Estimate Pi\n",
        "    if square_points == 0:\n",
        "        return 0.0\n",
        "    pi_estimate = 4 * circle_points / square_points\n",
        "    return pi_estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8279cbf8",
      "metadata": {
        "id": "8279cbf8",
        "outputId": "375cb043-d58c-4ed9-8cc4-7447cb436d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Estimation of Pi (QRNG) = 3.1408\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    INTERVAL = 50\n",
        "    TOTAL_POINTS = INTERVAL ** 2\n",
        "    qrng = QRNGaaS(API_KEY)\n",
        "    pi = estimate_pi_qrng(TOTAL_POINTS, qrng)\n",
        "    print(f\"Final Estimation of Pi (QRNG) = {pi}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "krispy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
