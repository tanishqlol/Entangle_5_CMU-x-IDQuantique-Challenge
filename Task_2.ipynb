{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports - feel free to add what you think might be useful! \n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import hashlib\n",
    "import struct \n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd5b50",
   "metadata": {},
   "source": [
    "## Task 2: Tinkering with True Randomness\n",
    "We've provided template classes for everything here. This task isn't meant to test your ability to write boilerplate code, rather we just want you to see the different environmental sources of entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are TODO tags where we want you to implement something. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af55384",
   "metadata": {},
   "source": [
    "### Part A: Jitter-bug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8506726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import time # to be able to measure natural timing variations (jitter)\n",
    "\"\"\" \n",
    "Important to Know:\n",
    "time.perf_counter_ns() is our measurement function from the time package.\n",
    "You will modify _collect_timing_jitter()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JitterRNG:\n",
    "    def __init__(self, pool_size=256):\n",
    "        self.entropy_pool = deque(maxlen=pool_size)\n",
    "        self.pool_size = pool_size\n",
    "        self.last_time = None\n",
    "    \n",
    "    def _collect_timing_jitter(self, iterations=1000):\n",
    "        \"\"\"Collect entropy from timing variations between CPU operations\"\"\"\n",
    "        jitter_data = []\n",
    "        \n",
    "        self.last_time = \"CHANGE ME\" # TODO: First measurement to initialize\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            \"\"\" \n",
    "            We need to introduce variability somehow. \n",
    "            In the following space, do some arbitrary computation to introduce variability.\n",
    "            We're not going to judge this part. Just make it reasonable so your notebook\n",
    "            doesn't take forever to run.\n",
    "            \"\"\"\n",
    "            # TODO: Do some arbitrary computation to introduce variability\n",
    "            \"\"\" \n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "            current_time = \"CHANGE ME\" # TODO: Measure the time again\n",
    "            assert current_time != \"CHANGE ME\" # delete this when you're done\n",
    "            \n",
    "            \n",
    "            time_diff = \"CHANGE ME\" # TODO: Calculate the jitter (timing difference)\n",
    "            # hint: the JitterRNG class has a last_time attribute, \n",
    "            # and you just computed the current time.\n",
    "            assert time_diff != \"CHANGE ME\" # delete this when you're done\n",
    "            \n",
    "            # Extract the least significant bits of the time difference\n",
    "            # This is where the true randomness comes from\n",
    "            lsb = \"CHANGE ME\" # TODO: Get the lowest 8 bits of time_diff\n",
    "            # hint: bitwise ops \n",
    "            assert lsb != \"CHANGE ME\" # delete this when you're done\n",
    "            jitter_data.append(lsb)\n",
    "\n",
    "            self.last_time = \"CHANGE ME\" # TODO: update self.last_time for next iteration\n",
    "            assert self.last_time != \"CHANGE ME\" # delete this when you're done\n",
    "\n",
    "        return jitter_data\n",
    "    \n",
    "    def fill_entropy_pool(self):\n",
    "        \"\"\"Fill the entropy pool with timing jitter data\"\"\"\n",
    "        # Collect enough jitter samples to fill the pool\n",
    "        jitter_data = self._collect_timing_jitter(self.pool_size)\n",
    "        \n",
    "        # Add to the entropy pool\n",
    "        for value in jitter_data:\n",
    "            self.entropy_pool.append(value)\n",
    "        \n",
    "        return jitter_data\n",
    "    \n",
    "    def get_random_bytes(self, num_bytes=32):\n",
    "        \"\"\"Generate random bytes using the entropy pool\"\"\"\n",
    "        # Make sure we have enough entropy\n",
    "        if len(self.entropy_pool) < self.pool_size:\n",
    "            self.fill_entropy_pool()\n",
    "        \n",
    "        # Mix the entropy pool using SHA-256\n",
    "        pool_bytes = bytes(self.entropy_pool)\n",
    "        mixed_entropy = hashlib.sha256(pool_bytes).digest()\n",
    "        \n",
    "        # Create an output buffer\n",
    "        result = bytearray()\n",
    "        \n",
    "        # Generate requested number of bytes\n",
    "        while len(result) < num_bytes:\n",
    "            # Add more entropy to the pool\n",
    "            self.fill_entropy_pool()\n",
    "            \n",
    "            # Mix new entropy with previous hash\n",
    "            pool_bytes = bytes(self.entropy_pool)\n",
    "            h = hashlib.sha256()\n",
    "            h.update(mixed_entropy)\n",
    "            h.update(pool_bytes)\n",
    "            mixed_entropy = h.digest()\n",
    "            \n",
    "            # Add to result\n",
    "            result.extend(mixed_entropy)\n",
    "        \n",
    "        # Return only the requested number of bytes\n",
    "        return bytes(result[:num_bytes])\n",
    "    \n",
    "    def get_random_int(self, min_val=0, max_val=100):\n",
    "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
    "        # Calculate how many bytes we need\n",
    "        range_size = max_val - min_val + 1\n",
    "        if range_size <= 0:\n",
    "            raise ValueError(\"Invalid range\")\n",
    "        \n",
    "        # Calculate how many bits we need\n",
    "        bits_needed = range_size.bit_length()\n",
    "        bytes_needed = (bits_needed + 7) // 8\n",
    "        \n",
    "        # Get random bytes\n",
    "        random_bytes = self.get_random_bytes(bytes_needed)\n",
    "        \n",
    "        # Convert bytes to integer\n",
    "        value = int.from_bytes(random_bytes, byteorder='big')\n",
    "        \n",
    "        # Map to our range\n",
    "        return min_val + (value % range_size)\n",
    "    \n",
    "    def analyze_randomness(self, sample_size=1000):\n",
    "        \"\"\"Analyze the randomness of the generator\"\"\"\n",
    "        # Generate samples\n",
    "        samples = []\n",
    "        for _ in range(sample_size):\n",
    "            samples.append(self.get_random_int(0, 255))\n",
    "        \n",
    "        # Create plots\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Plot 1: Distribution histogram\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.hist(samples, bins=32, color='blue', alpha=0.7)\n",
    "        plt.title('Distribution of Random Values')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "        # Plot 2: Sequential values\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(samples[:100], '.-', alpha=0.7)\n",
    "        plt.title('First 100 Generated Values')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "        # Plot 3: Scatter plot of consecutive values\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.scatter(samples[:-1], samples[1:], alpha=0.5, s=5)\n",
    "        plt.title('Scatter Plot of Consecutive Values')\n",
    "        plt.xlabel('Value n')\n",
    "        plt.ylabel('Value n+1')\n",
    "        \n",
    "        # Plot 4: Autocorrelation\n",
    "        plt.subplot(2, 2, 4)\n",
    "        autocorr = np.correlate(samples, samples, mode='full')\n",
    "        autocorr = autocorr[len(autocorr)//2:]\n",
    "        autocorr = autocorr / autocorr[0]\n",
    "        plt.plot(autocorr[:50])\n",
    "        plt.title('Autocorrelation')\n",
    "        plt.xlabel('Lag')\n",
    "        plt.ylabel('Correlation')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5570e",
   "metadata": {},
   "source": [
    "We can use our jitter-based randomness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "jitter_rng = JitterRNG()\n",
    "random_data = jitter_rng.analyze_randomness(1000)\n",
    "print(f\"First 10 random numbers: {random_data[:10]}\")\n",
    "\n",
    "# Simulate rolling a die 20 times\n",
    "print(\"\\nRolling a die 20 times:\")\n",
    "for _ in range(20):\n",
    "    print(jitter_rng.get_random_int(1, 6), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04daba",
   "metadata": {},
   "source": [
    "### Part B: What's That Sound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "%pip install pyaudio\n",
    "import pyaudio\n",
    "\"\"\" \n",
    "Important to Know:\n",
    "You will only be modifying the collect_entropy() method. \n",
    "Read the rest of the methods in MicrophoneRNG if you get stuck.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13553852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneRNG:\n",
    "    def __init__(self, sample_rate=44100, chunk_size=1024, format=pyaudio.paInt16):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.format = format\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        self.stream = None\n",
    "        self.entropy_pool = bytearray()\n",
    "    \n",
    "    def _start_stream(self):\n",
    "        \"\"\"Start audio stream if not already running\"\"\"\n",
    "        if self.stream is None or not self.stream.is_active():\n",
    "            self.stream = self.audio.open(\n",
    "                format=self.format,\n",
    "                channels=1,\n",
    "                rate=self.sample_rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=self.chunk_size\n",
    "            )\n",
    "    \n",
    "    def _stop_stream(self):\n",
    "        \"\"\"Stop audio stream if running\"\"\"\n",
    "        if self.stream is not None and self.stream.is_active():\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "            self.stream = None\n",
    "    \n",
    "    def collect_entropy(self, duration_seconds=0.5, visualize=False):\n",
    "        \"\"\"Collect entropy from microphone for specified duration\"\"\"\n",
    "        \"CHANGE ME\" # TODO: start the stream\n",
    "        \n",
    "        frames = []\n",
    "        num_chunks = \"CHANGE ME\" # TODO: compute the number of chunks using the sample rate, duration in seconds, and chunk size. \n",
    "        # hint: there is a division involved. make sure to cast to int, or use integer division.\n",
    "        assert num_chunks != \"CHANGE ME\" # delete this when you're done\n",
    "        \n",
    "        print(f\"Collecting ambient noise for {duration_seconds} seconds...\")\n",
    "        \n",
    "        # Read audio data\n",
    "        for _ in range(max(1, num_chunks)):\n",
    "            data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "        \n",
    "        # Convert to numpy array for processing\n",
    "        if self.format == pyaudio.paInt16:\n",
    "            format_size = 2  # bytes per sample\n",
    "            format_char = 'h'  # short integer\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported audio format\")\n",
    "        \n",
    "        # Unpack audio data\n",
    "        audio_data = []\n",
    "        for frame in frames:\n",
    "            count = len(frame) // format_size\n",
    "            fmt = f\"{count}{format_char}\"\n",
    "            audio_data.extend(struct.unpack(fmt, frame))\n",
    "        \n",
    "        # Extract entropy from least significant bits\n",
    "        raw_entropy = bytearray()\n",
    "        for sample in audio_data:\n",
    "            # Take the least significant byte (where noise is most prominent)\n",
    "            \n",
    "            lsb = \"CHANGE ME\" # TODO: Get the lowest 8 bits of sample\n",
    "            # hint: bitwise ops, just like in Part A \n",
    "            assert lsb != \"CHANGE ME\" # delete this when you're done\n",
    "\n",
    "            raw_entropy.append(lsb)\n",
    "        \n",
    "        # Visualize if requested\n",
    "        if visualize:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Plot raw audio waveform\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(audio_data[:1000])\n",
    "            plt.title(\"Raw Audio Waveform (first 1000 samples)\")\n",
    "            plt.xlabel(\"Sample\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "            \n",
    "            # Plot histogram of the extracted entropy bytes\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.hist(raw_entropy, bins=32, color='green', alpha=0.7)\n",
    "            plt.title(\"Distribution of Extracted Entropy Bytes\")\n",
    "            plt.xlabel(\"Byte Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Add to entropy pool\n",
    "        self.entropy_pool.extend(raw_entropy)\n",
    "        \n",
    "        return raw_entropy\n",
    "    \n",
    "    def get_random_bytes(self, num_bytes=32):\n",
    "        \"\"\"Generate random bytes from the entropy pool\"\"\"\n",
    "        # Make sure we have enough entropy\n",
    "        while len(self.entropy_pool) < num_bytes * 2:  # Get more than we need\n",
    "            self.collect_entropy(0.1)\n",
    "        \n",
    "        # Mix entropy with SHA-256\n",
    "        h = hashlib.sha256()\n",
    "        h.update(self.entropy_pool)\n",
    "        \n",
    "        # Get a seed from the hash\n",
    "        seed = h.digest()\n",
    "        \n",
    "        # Generate additional random bytes using the seed\n",
    "        result = bytearray()\n",
    "        counter = 0\n",
    "        \n",
    "        while len(result) < num_bytes:\n",
    "            # Create a unique input for each iteration\n",
    "            h = hashlib.sha256()\n",
    "            h.update(seed)\n",
    "            h.update(counter.to_bytes(4, byteorder='big'))\n",
    "            result.extend(h.digest())\n",
    "            counter += 1\n",
    "        \n",
    "        # Remove used entropy from the pool\n",
    "        self.entropy_pool = self.entropy_pool[num_bytes:]\n",
    "        \n",
    "        return bytes(result[:num_bytes])\n",
    "    \n",
    "    def get_random_int(self, min_val=0, max_val=100):\n",
    "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
    "        range_size = max_val - min_val + 1\n",
    "        if range_size <= 0:\n",
    "            raise ValueError(\"Invalid range\")\n",
    "        \n",
    "        # Calculate how many bits we need\n",
    "        bits_needed = range_size.bit_length()\n",
    "        bytes_needed = (bits_needed + 7) // 8\n",
    "        \n",
    "        # Get random bytes\n",
    "        random_bytes = self.get_random_bytes(bytes_needed)\n",
    "        \n",
    "        # Convert to integer and map to our range\n",
    "        value = int.from_bytes(random_bytes, byteorder='big')\n",
    "        return min_val + (value % range_size)\n",
    "    \n",
    "    def visualize_randomness(self, num_samples=1000):\n",
    "        \"\"\"Generate and visualize random numbers\"\"\"\n",
    "        samples = [self.get_random_int(0, 255) for _ in range(num_samples)]\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Plot 1: Distribution histogram\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.hist(samples, bins=32, color='blue', alpha=0.7)\n",
    "        plt.title('Distribution of Random Values')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "        # Plot 2: Sequential values\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(samples[:100], '.-', alpha=0.7)\n",
    "        plt.title('First 100 Generated Values')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "        # Plot 3: Scatter plot of consecutive values\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.scatter(samples[:-1], samples[1:], alpha=0.5, s=5)\n",
    "        plt.title('Scatter Plot of Consecutive Values')\n",
    "        plt.xlabel('Value n')\n",
    "        plt.ylabel('Value n+1')\n",
    "        \n",
    "        # Plot 4: Autocorrelation\n",
    "        plt.subplot(2, 2, 4)\n",
    "        autocorr = np.correlate(samples, samples, mode='full')\n",
    "        autocorr = autocorr[len(autocorr)//2:]\n",
    "        autocorr = autocorr / autocorr[0]\n",
    "        plt.plot(autocorr[:50])\n",
    "        plt.title('Autocorrelation')\n",
    "        plt.xlabel('Lag')\n",
    "        plt.ylabel('Correlation')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up when object is destroyed\"\"\"\n",
    "        self._stop_stream()\n",
    "        self.audio.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64bcb08",
   "metadata": {},
   "source": [
    "We can use our audio-based randomness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a89123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    mic_rng = MicrophoneRNG()\n",
    "    \n",
    "    # Collect and visualize raw entropy\n",
    "    mic_rng.collect_entropy(duration_seconds=1.0, visualize=True)\n",
    "    \n",
    "    # Generate and visualize random numbers\n",
    "    random_data = mic_rng.visualize_randomness(1000)\n",
    "    \n",
    "    print(f\"First 10 random numbers: {random_data[:10]}\")\n",
    "    \n",
    "    # Simulate rolling a die 20 times\n",
    "    print(\"\\nRolling a die 20 times:\")\n",
    "    for _ in range(20):\n",
    "        print(mic_rng.get_random_int(1, 6), end=\" \")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Note: You may need to install pyaudio: pip install pyaudio\")\n",
    "    print(\"On some systems, you may need additional libraries:\")\n",
    "    print(\"  - Windows: pip install pipwin, then pipwin install pyaudio\")\n",
    "    print(\"  - macOS: brew install portaudio, then pip install pyaudio\")\n",
    "    print(\"  - Linux: sudo apt-get install python3-pyaudio or equivalent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e9368",
   "metadata": {},
   "source": [
    "### Part C: Things Are Heating Up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98259bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "%pip install psutil\n",
    "import psutil\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bc681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalRNG:\n",
    "    def __init__(self, pool_size=256):\n",
    "        self.entropy_pool = deque(maxlen=pool_size)\n",
    "        self.pool_size = pool_size\n",
    "        self.temperature_history = []\n",
    "        self.has_temperature_sensor = self._check_sensor_availability()\n",
    "    \n",
    "    def _check_sensor_availability(self):\n",
    "        \"\"\"Check if temperature sensors are available\"\"\"\n",
    "        try:\n",
    "            # Try to get temperatures\n",
    "            temps = self._get_temperature_data()\n",
    "            return len(temps) > 0\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def _get_temperature_data(self):\n",
    "        \"\"\"Get temperature data from system sensors\"\"\"\n",
    "        try:\n",
    "            if platform.system() == 'Windows':\n",
    "                %pip install wmi\n",
    "                import wmi\n",
    "                w = wmi.WMI(namespace=\"root\\\\wmi\")\n",
    "                temperature_info = w.MSAcpi_ThermalZoneTemperature()\n",
    "                temps = [float(item.CurrentTemperature) / 10.0 - 273.15 for item in temperature_info]\n",
    "                return temps\n",
    "            elif platform.system() == 'Linux':\n",
    "                # Use psutil on Linux\n",
    "                temperatures = psutil.sensors_temperatures()\n",
    "                temps = []\n",
    "                for name, entries in temperatures.items():\n",
    "                    for entry in entries:\n",
    "                        if entry.current is not None:\n",
    "                            temps.append(entry.current)\n",
    "                return temps\n",
    "            elif platform.system() == 'Darwin':  # macOS\n",
    "                # macOS temperature requires additional libraries\n",
    "                # This is a simplified fallback using CPU metrics as a proxy for temperature\n",
    "                cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
    "                return cpu_percent  # Using CPU load as a proxy for temperature\n",
    "            else:\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting temperature data: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _get_system_load(self):\n",
    "        \"\"\"Get system load information as a source of entropy\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        # CPU usage\n",
    "        cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
    "        data.extend(cpu_percent)\n",
    "        \n",
    "        # Memory usage\n",
    "        memory = psutil.virtual_memory()\n",
    "        data.append(memory.percent)\n",
    "        \n",
    "        # Disk usage\n",
    "        disk = psutil.disk_usage('/')\n",
    "        data.append(disk.percent)\n",
    "        \n",
    "        # Network IO counters\n",
    "        net = psutil.net_io_counters()\n",
    "        data.extend([net.bytes_sent % 256, net.bytes_recv % 256])\n",
    "        \n",
    "        return data\n",
    " \n",
    "    def collect_entropy(self, iterations=10, delay=0.1):\n",
    "        \"\"\"Collect entropy from temperature and system metrics\"\"\"\n",
    "        print(\"Collecting entropy from system metrics...\")\n",
    "        \n",
    "        raw_entropy = []\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            temps = \"CHANGE ME\" # TODO: Get temperature data\n",
    "            assert temps != \"CHANGE ME\" # delete this when you're done\n",
    "\n",
    "            # If temperature sensors are available, use them\n",
    "            if temps and len(temps) > 0:\n",
    "                self.has_temperature_sensor = True\n",
    "                for temp in temps:\n",
    "                    # Extract fractional part of temperature (most random part)\n",
    "                    frac_part = int((temp % 1) * 256)\n",
    "                    lsb = \"CHANGE ME\" # TODO: Get the lowest 8 bits of frac_part\n",
    "                    # hint: bitwise ops, just like in Part A \n",
    "                    assert lsb != \"CHANGE ME\" # delete this when you're done\n",
    "\n",
    "                    raw_entropy.append(lsb)\n",
    "                    self.temperature_history.append(temp)\n",
    "            \n",
    "            # Always collect system load data as additional entropy\n",
    "            system_data = self._get_system_load()\n",
    "            for value in system_data:\n",
    "                # Extract least significant bits\n",
    "                lsb = \"CHANGE ME\" # TODO: Get the lowest 8 bits of int(value)\n",
    "                # hint: bitwise ops, just like in Part A \n",
    "                assert lsb != \"CHANGE ME\" # delete this when you're done\n",
    "                \n",
    "                raw_entropy.append(lsb)\n",
    "            \n",
    "            # Small delay to allow for changes in system state\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        # Add to entropy pool\n",
    "        for value in raw_entropy:\n",
    "            self.entropy_pool.append(value)\n",
    "        \n",
    "        return raw_entropy\n",
    "    def ensure_entropy(self, min_required=128):\n",
    "        \"\"\"Ensure we have enough entropy in the pool\"\"\"\n",
    "        if len(self.entropy_pool) < min_required:\n",
    "            self.collect_entropy(iterations=max(1, (min_required - len(self.entropy_pool)) // 10))\n",
    "    \n",
    "    def get_random_bytes(self, num_bytes=32):\n",
    "        \"\"\"Generate random bytes from the entropy pool\"\"\"\n",
    "        # Make sure we have enough entropy\n",
    "        self.ensure_entropy(num_bytes * 2)\n",
    "        \n",
    "        # Mix entropy with SHA-256\n",
    "        h = hashlib.sha256()\n",
    "        h.update(bytes(self.entropy_pool))\n",
    "        \n",
    "        # Get a seed from the hash\n",
    "        seed = h.digest()\n",
    "        \n",
    "        # Generate additional random bytes using the seed\n",
    "        result = bytearray()\n",
    "        counter = 0\n",
    "        \n",
    "        while len(result) < num_bytes:\n",
    "            # Create a unique input for each iteration\n",
    "            h = hashlib.sha256()\n",
    "            h.update(seed)\n",
    "            h.update(counter.to_bytes(4, byteorder='big'))\n",
    "            result.extend(h.digest())\n",
    "            counter += 1\n",
    "        \n",
    "        # Collect more entropy for future use\n",
    "        self.collect_entropy(iterations=2)\n",
    "        \n",
    "        return bytes(result[:num_bytes])\n",
    "    \n",
    "    def get_random_int(self, min_val=0, max_val=100):\n",
    "        \"\"\"Generate a random integer between min_val and max_val (inclusive)\"\"\"\n",
    "        range_size = max_val - min_val + 1\n",
    "        if range_size <= 0:\n",
    "            raise ValueError(\"Invalid range\")\n",
    "        \n",
    "        # Calculate how many bits we need\n",
    "        bits_needed = range_size.bit_length()\n",
    "        bytes_needed = (bits_needed + 7) // 8\n",
    "        \n",
    "        # Get random bytes\n",
    "        random_bytes = self.get_random_bytes(bytes_needed)\n",
    "        \n",
    "        # Convert to integer and map to our range\n",
    "        value = int.from_bytes(random_bytes, byteorder='big')\n",
    "        return min_val + (value % range_size)\n",
    "    \n",
    "    def analyze_entropy_source(self):\n",
    "        \"\"\"Analyze and visualize the entropy sources\"\"\"\n",
    "        # Collect some entropy first\n",
    "        if len(self.entropy_pool) < 100:\n",
    "            self.collect_entropy(iterations=20)\n",
    "        \n",
    "        # Convert deque to list for analysis\n",
    "        entropy_data = list(self.entropy_pool)\n",
    "        \n",
    "        # Create plots\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Plot 1: Histogram of entropy values\n",
    "        axs[0, 0].hist(entropy_data, bins=50, density=True, alpha=0.7)\n",
    "        axs[0, 0].set_title('Distribution of Entropy Values')\n",
    "        axs[0, 0].set_xlabel('Value')\n",
    "        axs[0, 0].set_ylabel('Frequency')\n",
    "        axs[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Time series of values\n",
    "        axs[0, 1].plot(entropy_data, '-o', markersize=3, alpha=0.7)\n",
    "        axs[0, 1].set_title('Entropy Values over Collection Period')\n",
    "        axs[0, 1].set_xlabel('Sample Index')\n",
    "        axs[0, 1].set_ylabel('Value')\n",
    "        axs[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Temperature history if available\n",
    "        if self.has_temperature_sensor and len(self.temperature_history) > 0:\n",
    "            axs[1, 0].plot(self.temperature_history, '-o', markersize=3, color='red', alpha=0.7)\n",
    "            axs[1, 0].set_title('Temperature History')\n",
    "            axs[1, 0].set_xlabel('Sample Index')\n",
    "            axs[1, 0].set_ylabel('Temperature (Â°C)')\n",
    "            axs[1, 0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axs[1, 0].text(0.5, 0.5, 'No temperature data available', \n",
    "                          horizontalalignment='center', verticalalignment='center',\n",
    "                          transform=axs[1, 0].transAxes, fontsize=14)\n",
    "        \n",
    "        # Plot 4: Autocorrelation (to check for patterns)\n",
    "        if len(entropy_data) > 10:\n",
    "            max_lag = min(50, len(entropy_data) // 2)\n",
    "            autocorr = [np.corrcoef(entropy_data[:-i], entropy_data[i:])[0, 1] \n",
    "                        if i > 0 else 1.0 for i in range(max_lag)]\n",
    "            \n",
    "            axs[1, 1].bar(range(max_lag), autocorr, alpha=0.7)\n",
    "            axs[1, 1].set_title('Autocorrelation Analysis')\n",
    "            axs[1, 1].set_xlabel('Lag')\n",
    "            axs[1, 1].set_ylabel('Correlation Coefficient')\n",
    "            axs[1, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add horizontal lines for significance levels (roughly 95% confidence)\n",
    "            sig_level = 1.96 / np.sqrt(len(entropy_data))\n",
    "            axs[1, 1].axhline(y=sig_level, color='r', linestyle='--', alpha=0.5)\n",
    "            axs[1, 1].axhline(y=-sig_level, color='r', linestyle='--', alpha=0.5)\n",
    "        else:\n",
    "            axs[1, 1].text(0.5, 0.5, 'Not enough data for autocorrelation', \n",
    "                          horizontalalignment='center', verticalalignment='center',\n",
    "                          transform=axs[1, 1].transAxes, fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Basic statistical analysis\n",
    "        print(\"\\nEntropy Source Analysis:\")\n",
    "        print(f\"Number of samples: {len(entropy_data)}\")\n",
    "        if len(entropy_data) > 0:\n",
    "            print(f\"Mean: {np.mean(entropy_data):.2f}\")\n",
    "            print(f\"Standard Deviation: {np.std(entropy_data):.2f}\")\n",
    "            print(f\"Min: {np.min(entropy_data)}\")\n",
    "            print(f\"Max: {np.max(entropy_data)}\")\n",
    "        \n",
    "        # Run basic entropy tests if enough data\n",
    "        if len(entropy_data) >= 100:\n",
    "            # Simple frequency test (values should be roughly uniformly distributed)\n",
    "            hist, _ = np.histogram(entropy_data, bins=16, range=(0, 255))\n",
    "            chi_squared = np.sum((hist - len(entropy_data)/16)**2 / (len(entropy_data)/16))\n",
    "            print(f\"\\nChi-squared uniformity test: {chi_squared:.2f}\")\n",
    "            print(\"(Lower values suggest better uniformity)\")\n",
    "            \n",
    "            # Serial correlation test\n",
    "            serial_corr = np.corrcoef(entropy_data[:-1], entropy_data[1:])[0, 1]\n",
    "            print(f\"Serial correlation: {serial_corr:.4f}\")\n",
    "            print(\"(Values close to zero suggest good randomness)\")\n",
    "        \n",
    "        return entropy_data\n",
    "    \n",
    "    def generate_random_sequence(self, length=100, min_val=0, max_val=255):\n",
    "        \"\"\"Generate a sequence of random numbers\"\"\"\n",
    "        return [self.get_random_int(min_val, max_val) for _ in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ThermalRNG\n",
    "thermal_rng = ThermalRNG()\n",
    "\n",
    "# Collect some initial entropy\n",
    "thermal_rng.collect_entropy(iterations=5)\n",
    "\n",
    "# Generate 20 random numbers between 0 and 100\n",
    "random_data = [thermal_rng.get_random_int(0, 100) for _ in range(20)]\n",
    "print(f\"First 10 random numbers: {random_data[:10]}\")\n",
    "\n",
    "# Simulate rolling a die 20 times\n",
    "print(\"\\nRolling a die 20 times:\")\n",
    "for _ in range(20):\n",
    "    print(thermal_rng.get_random_int(1, 6), end=\" \")\n",
    "print()\n",
    "\n",
    "# Generate random bytes\n",
    "random_bytes = thermal_rng.get_random_bytes(16)\n",
    "print(f\"\\nRandom bytes (hex): {random_bytes.hex()}\")\n",
    "\n",
    "# Quick coin flip simulation (10 flips)\n",
    "print(\"\\nFlipping a coin 10 times (0=Heads, 1=Tails):\")\n",
    "for _ in range(10):\n",
    "    print(\"H\" if thermal_rng.get_random_int(0, 1) == 0 else \"T\", end=\" \")\n",
    "print()\n",
    "\n",
    "# Generate a number from a larger range\n",
    "big_number = thermal_rng.get_random_int(1, 1000000)\n",
    "print(f\"\\nRandom number between 1 and 1,000,000: {big_number}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
